# ğŸ§  Mon Agent LLM (gratuit avec Hugging Face)

Ce projet est un **agent conversationnel intelligent**, construit avec un modÃ¨le LLM open-source hÃ©bergÃ© sur Hugging Face et enrichi par une base de connaissances via RAG (Retrieval-Augmented Generation).

---

## ğŸ”§ Objectif du projet

CrÃ©er un chatbot qui :
- Utilise un modÃ¨le open-source (`Mixtral-8x7B-Instruct`)
- Fonctionne gratuitement via lâ€™API Inference de Hugging Face
- Est enrichi par une base de donnÃ©es locale (RAG)
- Peut Ãªtre utilisÃ© dans le terminal ou via une interface Streamlit
- Est facile Ã  personnaliser


---


## ğŸ“š Fonctionnement gÃ©nÃ©ral

Lâ€™agent utilise une combinaison de techniques :
- ğŸ” **FAISS** pour retrouver les documents les plus pertinents dans une base locale (questions-rÃ©ponses)
- ğŸ¤– **LLM** pour gÃ©nÃ©rer une rÃ©ponse contextualisÃ©e Ã  partir des documents rÃ©cupÃ©rÃ©s
- ğŸ›ï¸ **TempÃ©rature** pour contrÃ´ler la crÃ©ativitÃ© de la rÃ©ponse gÃ©nÃ©rÃ©e (ex : 0.1 = rÃ©ponse trÃ¨s prÃ©cise, 1.0 = plus libre)

> ğŸ’¡ *La tempÃ©rature est un paramÃ¨tre influenÃ§ant le degrÃ© de "crÃ©ativitÃ©" du modÃ¨le : plus elle est basse, plus les rÃ©ponses sont dÃ©terministes. Une tempÃ©rature de 0.7 est un bon Ã©quilibre pour un agent informatif comme un assistant de voyage.*



### objectif de agent.py

crÃ©er un chatbot local qui:
- charge un modÃ¨le LLM open-source depuis haggingface
- lit la clÃ© API depuis un fichier .env
- fontionne dans le terminal
- rÃ©pond Ã  tes questions jusqu'Ã  ce que tu tapes exit

---

## ğŸ’» Technologies utilisÃ©es

- [Transformers (Hugging Face)](https://huggingface.co/docs/transformers)
- [Huggingface Hub](https://huggingface.co/docs/huggingface_hub)
- [FAISS (Facebook AI Similarity Search)](https://github.com/facebookresearch/faiss)
- [Sentence Transformers](https://www.sbert.net/)
- [Streamlit](https://streamlit.io/)
- Python 3.10+
---

## ğŸš€ Lancer le projet

### 1. Cloner le projet (ou crÃ©er ton dossier)


```bash
git clone https://github.com/mon-utilisateur/mon_agent_llm.git
cd mon_agent_llm
```
pour crÃ©er le dossier : 

```bash
mkdir mon_agent_llm
cd mon_agent_llm
code . # ouvrir le dossier dans vscode
```
### 2. CrÃ©er un environnement virtuel 

```bash
python -m venv .venv
.venv\Scripts\activate # sous Windows
# ou source .venv/bin/activate  # sous Mac/Linux

```

### 3. Installer les dÃ©pendances 

pip install -r requirements.txt


### 4. CrÃ©er un compte hugging face et une clÃ©

1. https://huggingface.co/join

2. GÃ©nÃ©rez une clÃ© ici : https://huggingface.co/settings/tokens

3. Permission : Read

### 5. ajouter la clÃ© huggingface dans un fichier .env

HUGGINGFACEHUB_API_TOKEN=ta_clÃ©_personnelle_ici


### 6. Lancer l'agent 
streamlit run agent.py


## Info utile:

## Pourquoi FAISS pour le RAG?

FAISS permet une recherche vectorielle rapide et efficace, en comparant les embeddings de la question de lâ€™utilisateur avec ceux des documents de la base. Câ€™est une solution adaptÃ©e pour les projets locaux sans backend complexe.


---

# ğŸ‡¬ğŸ‡§ English Version â€“ `README.md`

```markdown
# ğŸ§  My LLM Agent (Free with Hugging Face + RAG)

This project is a **simple conversational agent** powered by an open-source LLM hosted on Hugging Face and enhanced with a local knowledge base using RAG (Retrieval-Augmented Generation).

---

## ğŸ”§ Project Goals

Build a chatbot that:
- Uses an open-source LLM (e.g. `Mixtral-8x7B-Instruct` or `Mistral-7B-Instruct`)
- Runs for free via the Hugging Face Inference API
- Retrieves knowledge from a local text base (RAG)
- Can be used in the terminal or via a visual Streamlit interface
- Is easy to customize and extend

---

## ğŸ“š How It Works

The agent combines:
- ğŸ” **FAISS** for fast similarity search over a local database (Q/A pairs)
- ğŸ¤– **LLM** to generate contextualized answers
- ğŸ›ï¸ **Temperature** to control creativity level (0.1 = deterministic, 1.0 = creative)

> ğŸ’¡ *Temperature controls how random or deterministic the modelâ€™s responses are. A value of 0.7 offers a good balance for informative assistants like a travel bot.*

---

## ğŸ“ Project Structure

mon_agent_llm/
â”‚
â”œâ”€â”€ agent.py # CLI-based chatbot
â”œâ”€â”€ app.py / test.py # Streamlit interface with RAG
â”œâ”€â”€ base_base.txt # Local text knowledge base
â”œâ”€â”€ .env # Hugging Face API token
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file ğŸ§ 


---

## ğŸ’» Tech Stack

- [Transformers (Hugging Face)](https://huggingface.co/docs/transformers)
- [Huggingface Hub](https://huggingface.co/docs/huggingface_hub)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Sentence Transformers](https://www.sbert.net/)
- [Streamlit](https://streamlit.io/)
- Python 3.10+

---

## ğŸš€ Run the Project

### 1. Clone the repo

```bash
git clone https://github.com/your-username/mon_agent_llm.git
cd mon_agent_llm

```

### 2. Create a virtual environment
```bash
python -m venv .venv
.venv\Scripts\activate  # On Windows
# Or source .venv/bin/activate  # On Mac/Linux
```

### 3. Install dependencies

```bash
pip install -r requirements.txt

```

### 4. Create a Hugging Face account & token

    https://huggingface.co/join

    Generate a token: https://huggingface.co/settings/tokens

    Permission: Read

the create a .venv file and add:
```bash 
HF_TOKEN=hf_your_personal_token

```
### 5. Launch the agent 

```bash
Streamlit run agent.py
```